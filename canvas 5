
#%% md
### IMPORTANT!!! Make sure you are using BinaryClassificationPerformance v1.03

#%%
help(BinaryClassificationPerformance)
#%% md
### file paths and names
#%%
ci_path = 'plane_data/cropped_images/' # file path for cropped images for training
l_file = 'plane_data/plane_labels.csv' # file path and file name for csv with labels
#%% md
# Function for feature building and extraction on photographs¶

scikit-image documentation on methods used for feature extraction:  

* http://scikit-image.org/docs/dev/api/skimage.color.html#rgb2gray  
* http://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.resize  
* http://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.canny
#%%
# in downscaling the image, what do you want the new dimensions to be?
# the original dimensions of cropped images: (60, 140), which if 8,400 pixels
dims = (15, 35) # 25% of the original size, 525 pixels
#%%
import os
import warnings
import cv2
import numpy as np
from skimage import io, transform, feature, filters, morphology, color

def corner_fast(image, threshold=10):
    img_8bit = (image * 255).astype(np.uint8)
    gray = cv2.cvtColor(img_8bit, cv2.COLOR_BGR2GRAY)
    fast = cv2.FastFeatureDetector_create(threshold)
    keypoints = fast.detect(gray, None)
    corner_image = cv2.drawKeypoints(img_8bit, keypoints, None, color=(255, 0, 0))
    return corner_image

def hog_features(image):
    hog_image = feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys')
    return hog_image

def image_manipulation(imname, imgs_path, imview=False):
    warnings.filterwarnings('ignore')

    imname = os.path.join(imgs_path, imname + '.png')
    img_raw = io.imread(imname, as_gray=True)

    # Apply HOG feature descriptor
    hog_image = hog_features(img_raw)

    # Dilate HOG features to make them more visible
    dilated_hog = morphology.dilation(hog_image)

    # Resize dilated HOG features to match the size of the original image
    dilated_hog = transform.resize(dilated_hog, img_raw.shape)

    # Convert dilated HOG features to binary image
    threshold = filters.threshold_otsu(dilated_hog)
    binary_hog = dilated_hog > threshold

    # Combine the original image and the binary HOG features
    final_image = color.gray2rgb(img_raw)
    final_image[binary_hog] = 1

    # Apply FAST corner detection
    final_image = corner_fast(final_image)

    if imview:
        io.imshow(final_image)

    warnings.filterwarnings('always')
    return final_image

test_image = image_manipulation('2017-08-25T23+24+13_390Z', ci_path, True)

#%%

#%% md
for comparison, look at original image:
#%%
this_imname = ci_path + '2017-08-25T23+24+13_390Z.png'
io.imshow(io.imread(this_imname))
#%% md
# function to process raw images, resulting in training and test datasets
#%%
# function that takes raw images and completes all preprocessing required before model fits
def process_raw_data(labels_fn, images_fp, my_random_seed, imview=False, test=False):
    plane_data = pd.read_csv(labels_fn) # read in photograph labels
    print("First few lines of image labels: ")
    print(plane_data.head())
    print("Size of image label dataFrame: ")
    print(plane_data.shape)
        
    # construct lists for features, labels, and a crosswalk reference to image names
    features_list = []
    if (not test):
        y_list = []
    imnames_list = []

    for index, row in plane_data.iterrows():
        features_list.append(image_manipulation(row['img_name'], images_fp))
        if (not test):
            y_list.append(row['plane'])
        imnames_list.append(row['img_name'])
    
    # convert the lists to ndarrays
    features = np.asarray(features_list)
    if (not test):
        Y = np.asarray(y_list)
    imgs = np.asarray(imnames_list)
    print('Shape of original feature representation: ')
    print(features.shape)

    # flatten the images ndarray to one row per image
    features_flat = features.reshape((features.shape[0], -1))

    print('Shape of flat feature representation: ')
    print(features_flat.shape)

    if (not test):
        print('Shape of Y: ')
        print(Y.shape)

        print('Number of images with planes: ')
        print(Y.sum())
    
        # create train and test sets
        data_train, data_test, y_train, y_test, imgs_train, imgs_test = train_test_split(features_flat, 
            Y, imgs, test_size = 0.25, random_state = my_random_seed)

        print('Shape of training set: ')
        print(y_train.shape)
        print('Number of training images that contain an airplane: ')
        print(y_train.sum())

        print('Shape of test set: ')
        print(y_test.shape)
        print('Number of test images that contain an airplane: ')
        print(y_test.sum())
    
    if (test):
        X_submission_test = features_flat
        print("Shape of X_test for submission:")
        print(X_submission_test.shape)
        print('SUCCESS!')
        return(X_submission_test, plane_data)
    else: 
        print("Shape of data_train and data_test:")
        print(data_train.shape)
        print(data_test.shape)
        print("Shape of y_train and y_test:")
        print(y_train.shape)
        print(y_test.shape)
        print("Shape of imgs_train and imgs_test:")
        print(imgs_train.shape)
        print(imgs_test.shape)
        print('SUCCESS!')
        return(data_train, data_test, y_train, y_test, imgs_train, imgs_test)

#%%
data_train, data_test, y_train, y_test, imgs_train, imgs_test = process_raw_data(l_file, ci_path, 
    my_random_seed=99, imview=False, test=False)
#%% md
# train Perceptron
#%%
# MODEL: Perceptron
from sklearn import linear_model
prc = linear_model.SGDClassifier(loss='perceptron')
prc.fit(data_train, y_train)

prc_performance = BinaryClassificationPerformance(prc.predict(data_train), y_train, 'prc')
prc_performance.compute_measures()
prc_performance.performance_measures['set'] = 'train'
print('TRAINING SET: ')
print(prc_performance.performance_measures)

prc_performance_test = BinaryClassificationPerformance(prc.predict(data_test), y_test, 'prc')
prc_performance_test.compute_measures()
prc_performance_test.performance_measures['set'] = 'test'
#%%

#%%
print('TEST SET: ')
print(prc_performance_test.performance_measures)

prc_performance_test.img_indices()
prc_img_indices_to_view = prc_performance_test.image_indices
#%%
def performance_examples(typ, measures):
    iiv = ''
    if typ == 'FP':
        iiv = typ + '_indices'
    elif typ == 'TP':
        iiv = typ + '_indices'
    elif typ == 'FN':
        iiv = typ + '_indices'
    else:
        raise ValueError('input must be "TP", "FP", or "FN"')
    for img in measures[iiv]:
        warnings.filterwarnings('ignore')    
        plt.figure()
        lookat = ci_path + imgs_test[img] + '.png' # location of original image
        io.imshow(lookat) # show original image
        plt.figure()
        io.imshow(data_test[img].reshape(dims[0], dims[1])) # show manipulation for feature representation
        warnings.filterwarnings('always')

#%% md
# look at examples of Perceptron classifications
#%% md
## true positives
#%%
# performance_examples('TP', prc_img_indices_to_view)
#%% md
## false positives
#%%
# performance_examples('FP', prc_img_indices_to_view)
#%% md
## false negatives
#%%
# performance_examples('FN', prc_img_indices_to_view)
#%% md

#%% md
# train Multilayer Perceptron, a.k.a. neural network
#%%
# MODEL: Multi-layer Perceptron aka neural network
from sklearn import neural_network
nn = neural_network.MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 100,100,100,100), random_state=1, max_iter= 5000) # lbfgs = Limited-memory Broyden–Fletcher–Goldfarb–Shanno.
print(nn)
nn.fit(data_train, y_train)

nn_performance = BinaryClassificationPerformance(nn.predict(data_train), y_train, 'nn')
nn_performance.compute_measures()
nn_performance.performance_measures['set'] = 'train'
print('TRAINING SET: ')
print(nn_performance.performance_measures)

nn_performance_test = BinaryClassificationPerformance(nn.predict(data_test), y_test, 'nn_test')
nn_performance_test.compute_measures()
nn_performance_test.performance_measures['set'] = 'test'
print('TEST SET: ')
print(nn_performance_test.performance_measures)

nn_performance_test.img_indices()
nn_img_indices_to_view = nn_performance_test.image_indices
#%% md
# look at examples of neural network classifications
#%% md
## true positives
#%%
# performance_examples('TP', nn_img_indices_to_view)
#%% md
## false positives
#%%
# performance_examples('FP', nn_img_indices_to_view)
#%% md
## false negatives
#%%
# performance_examples('FN', nn_img_indices_to_view)
#%% md
# comparisons
#%%
# list of fits to compare: 
final_fits = []
final_fits.append(prc_performance.performance_measures)
final_fits.append(prc_performance_test.performance_measures)
final_fits.append(nn_performance.performance_measures)
final_fits.append(nn_performance_test.performance_measures)
#%%
plt.figure(figsize=(10,10))

for fit in final_fits:
    if fit['set'] == 'train':
        color = 'co'
    else:
        color = 'ro'
    plt.plot(fit['FP'] / fit['Neg'], 
             fit['TP'] / fit['Pos'], color, markersize=12)
    plt.text(fit['FP'] / fit['Neg'], 
             fit['TP'] / fit['Pos'], fit['desc'] + ': ' + fit['set'], fontsize=16)
plt.axis([0, 1, 0, 1])
plt.title('ROC plot: test set')
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.show()

#%%
# MODEL: Multi-layer Perceptron aka neural network
from sklearn import neural_network

# Configurations for hidden layers
hidden_layer_configs = [
    (50,),
    (200,),
    (50, 100),
    (50, 100, 150),
    (100, 80, 60, 40, 20)
]

# List to store performance measures of each model
final_fits = []

# Train and evaluate MLP models for each configuration
for i, hidden_layer_sizes in enumerate(hidden_layer_configs):
    nn = neural_network.MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=hidden_layer_sizes, random_state=1, max_iter=2000)
    print(f"MLP model {i+1} with hidden layers: {hidden_layer_sizes}")
    nn.fit(data_train, y_train)

    nn_performance = BinaryClassificationPerformance(nn.predict(data_train), y_train, f'nn_{i+1}')
    nn_performance.compute_measures()
    nn_performance.performance_measures['set'] = 'train'
    print('TRAINING SET: ')
    print(nn_performance.performance_measures)
    final_fits.append(nn_performance.performance_measures)

    nn_performance_test = BinaryClassificationPerformance(nn.predict(data_test), y_test, f'nn_test_{i+1}')
    nn_performance_test.compute_measures()
    nn_performance_test.performance_measures['set'] = 'test'
    print('TEST SET: ')
    print(nn_performance_test.performance_measures)
    final_fits.append(nn_performance_test.performance_measures)

    nn_performance_test.img_indices()
    nn_img_indices_to_view = nn_performance_test.image_indices

#%%
plt.figure(figsize=(10,10))

for fit in final_fits:
    if fit['set'] == 'train':
        facecolor = 'c'
        marker = 'o'
    else:
        facecolor = 'r'
        marker = 's'

    hidden_layer_str = str(fit['desc']).split('_')[1] if 'nn_test' in fit['desc'] else ''

    plt.scatter(fit['FP'] / fit['Neg'],
                fit['TP'] / fit['Pos'], c=facecolor, marker=marker, s=100, label=fit['desc'] + ': ' + fit['set'] + ' ' + hidden_layer_str)
    plt.text(fit['FP'] / fit['Neg'] + 0.02,
             fit['TP'] / fit['Pos'] - 0.02, fit['desc'] + ': ' + fit['set'] + ' ' + hidden_layer_str, fontsize=12)

plt.axis([0, 1, 0, 1])
plt.title('ROC plot: test set')
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.legend(loc='best')
plt.show()
#%% md
# SUBMISSION

### file paths and names:
#%%
# submission_ci_path = 'test_data_for_grading/test_cropped_images/' # file path for cropped images for training
# submission_l_file = 'test_data_for_grading/test_plane_labels.csv' # file path and file name for csv with labels
#%%
# X_test_data, X_test_submission = process_raw_data(submission_l_file, submission_ci_path, my_random_seed=99, test=True)
# print("Number of rows in the submission test set (should be 1,523): ")
#%% md
### IMPORTANT CHECK: make sure that the number of columns in your training data is the same as the number of columns in this test submission!
#%%
# print(data_train.shape)
# print(X_test_data.shape)
#%% md
Both the training set and submission test set have 525 columns. Success!
#%% md
---

Choose a *single* model for your submission. In this code, I am choosing the Perceptron model fit, which is in the prc object. But you should choose the model that is performing the best for you!
#%%
# # concatenate predictions to the id
# X_test_submission["prediction"] = prc.predict(X_test_data)
# # look at the proportion of positive predictions
# print(X_test_submission['prediction'].mean())
#%% md
This is the proportion of predictions that have predicted that there is an airplane in the image.
#%%
# print(X_test_submission.shape) # should be (1523, 2)
#%%
# # export submission file as pdf
# # CHANGE FILE PATH:
